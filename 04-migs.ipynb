{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2327b2d-7ce9-44ce-96d2-c0eacee8f585",
   "metadata": {},
   "source": [
    "# CIP203 - Maximizing GPU usage with MIGs, MPS, and Time-Slicing: \n",
    "## Nvidia MIGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f376a-92af-4496-b23f-b426fceda8e2",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* How to speed-up my code with the use of MIGs ?\n",
    "\n",
    "**Objectives**\n",
    "* Get familiarized with the concept of NVIDIA MIG\n",
    "* Learn how to change your submission script to request MIG instead of full GPU\n",
    "* Practice running examples on MIG instances and do bechmarking "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba3f68-1a97-4876-b60a-e8b6ebf562e9",
   "metadata": {},
   "source": [
    "### What is MIG ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4199b-7a9c-4c31-873c-63fbd9295eca",
   "metadata": {},
   "source": [
    "Multi-Instance GPU (MIG) is a technology that allows partitioning of a single GPU into multiple smaller, isolated GPU instances. Now a single GPU can be shared between different jobs and users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d9787-e795-4b22-bc6e-359830aacf03",
   "metadata": {},
   "source": [
    "### Some features:\n",
    "- GPUs are securely partitioned into up to 7 instances\n",
    "- guaranteed resource allocation (compute, memory, cache)\n",
    "- predictable performance for workloads like AI training, inference, and HPC\n",
    "- Each instance gets a unique and dedicated set of hardware resources\n",
    "- Users can choose MIG instances of various sizes to match the specific requirements of different workloads, optimizing resource allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7f729-22ce-4bd4-90c4-c358b3924424",
   "metadata": {},
   "source": [
    "![alt text](./images/gpu-mig-overview.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad32a72-d8b1-462d-bf7b-fa2343a462a3",
   "metadata": {},
   "source": [
    "#### Any MIG capable GPU starting with A100 can be split into 7 physically discrete instances:\n",
    "- memory is split into 8 equal size segments\n",
    "- compute units are also split into 8 segment, but only 7 are available to MIGs\n",
    "- this implies the overhead of 10% of compute power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812ee29-4b41-4300-af60-9a9ca4d2e88b",
   "metadata": {},
   "source": [
    "### Available MIG configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957fcea-6258-4e3d-aeb7-815fca80e12f",
   "metadata": {},
   "source": [
    "While there are many possible MIG configurations and profiles, the supported profiles are system dependant. For example, for A100 GPU the list of MIG configurations is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e636e2-0dec-4949-bb7b-9811c768a170",
   "metadata": {},
   "source": [
    "![alt text](./images/A100-migs.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259f3e3-6062-41fb-bff6-0e57072ce6fc",
   "metadata": {},
   "source": [
    "The profile name describes the size of the instance. For example, a 3g.20gb instance has 20 GB of GPU memory and offers 3/8th of the computing performance of a full GPU. To list all the flavours of MIGs (plus the full size GPU names) available on a given cluster, one can run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73bc549-c10e-43a2-900f-b30d9c67bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1g.5gb\n",
      "3g.20gb\n"
     ]
    }
   ],
   "source": [
    "! sinfo -o \"%G\"|grep gpu|sed 's/gpu://g'|sed 's/,/\\n/g'|cut -d: -f1|sort|uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df42330-0038-4537-b43d-26e2beeb6e62",
   "metadata": {},
   "source": [
    "### What changes are required to switch to using MIGs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ceaec-def2-4c15-a684-22a5fd4e11a9",
   "metadata": {},
   "source": [
    "You don't have to change anything in your code. You only need to request a MIG instead of a full body GPU. For example, a request for the interactive job will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeaf429-9502-428b-a8fc-4a911851ee88",
   "metadata": {},
   "source": [
    "salloc --account=def-someuser --gpus=<font color='red'>**3g.20gb**</font>:1 --cpus-per-task=2 --mem=40gb --time=1:0:0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331aa6c-da32-436a-8ac2-9c21199270f9",
   "metadata": {},
   "source": [
    "Pay attention to the profile name here <font color='red'>**3g.20gb**</font>. It may be different on other clusters. For example, on Narval the batch submission script with MIG request will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1c1bd-5a94-41f3-abb7-6c81a16460e1",
   "metadata": {},
   "source": [
    "![alt text](./images/mig-script-narval.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1afe7f-f462-4f32-90af-8922557f8a48",
   "metadata": {},
   "source": [
    "### Why should I use MIG instead of a full GPU ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4b3cd-944f-4b22-97d3-48b990c72470",
   "metadata": {},
   "source": [
    "- using GPU instances is less wasteful\n",
    "- your usage is billed accordingly\n",
    "- jobs submitted on such instances use less of your allocated priority compared to a full GPU\n",
    "- you will then be able to execute more jobs and have shorter wait time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035466fa-9825-4b70-9508-5a7ecd0fae44",
   "metadata": {},
   "source": [
    "### How do I know whether I should choose MIG or a full GPU ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c71254-bf07-46cd-ad92-37597e68156e",
   "metadata": {},
   "source": [
    "- Jobs that use less than half of the computing power of a full GPU and less than half of the available memory should be evaluated and tested on an instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d671a6-8d90-4bdd-aa63-705da16c027e",
   "metadata": {},
   "source": [
    "### After migrating to MIGs: test your code to make sure it performs well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1169d3-2898-458c-9280-873d940a1bcb",
   "metadata": {},
   "source": [
    "You need to test your code by running different MIG profiles:\n",
    "1. Check how much GPU memory your code requires\n",
    "2. Run your code with the smallest possible MIG profile\n",
    "3. If your code fails due to out-of-memory errror, then do step 4\n",
    "4. Run your code using a bigger MIG profile with more GPU memory\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399739be-5115-4467-8f0e-8066acf4de67",
   "metadata": {},
   "source": [
    "### Exercise 3: Testing matrix multiplication code on different MIG profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778fb22-6e4d-4bd8-b29a-d5d715340b60",
   "metadata": {},
   "source": [
    "Our virtual machine (VM) is built with Magic Castle and has the following MIG profiles available for our tests:<br>\n",
    "<font color='red'>**1g.5gb**</font><br>\n",
    "<font color='red'>**3g.20gb**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12a4ee-8eef-4f1e-b649-496a25a1c78b",
   "metadata": {},
   "source": [
    "We will be using a Terminal to modify the PyTorch code and submit sbatch jobs.<br>\n",
    "1. To open a Termimal do File->New Launcher->Terminal\n",
    "2. In the terminal go to ~/cq-formation-cip203-main\n",
    "3. Then open the file matmul-mig.py and modify it if needed\n",
    "4. Then open the submission script submit-mig.sh and modify it if needed\n",
    "\n",
    "For <font color='red'>**1g.5gb**</font> profile please run the script on the node directly:<br>\n",
    "python ./matmul-mig.py\n",
    "\n",
    "For <font color='red'>**3g.20gb**</font> profile submit the sbatch job:<br>\n",
    "sbatch ./submit-mig.sh <br>\n",
    "\n",
    "The result is written to output file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649d66b-93bb-46ce-b232-58ea168cd174",
   "metadata": {},
   "source": [
    "#### Tests to be performed:\n",
    "1. Change matrix size to make problem more or less GPU memory hungry\n",
    "2. See if your code runs on 1g.5gb profile. If not, try 3g.30gb. If not, then you may need the full GPU.\n",
    "3. Execute the same problem on 1g.5gb and 3g.20gb proiles. Notice the difference in execution time. If execution time is about the same, then 1g.5g is all you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba382e-4fb4-4fe1-a500-99f54ba5c4e9",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec48ed-56a5-4370-8c0d-6240a88db49b",
   "metadata": {},
   "source": [
    "* **What is MIG**\n",
    "* **MIG: full physical isolation**\n",
    "* **Who profits from using MIGs**\n",
    "* **Testing code for better MIG configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d61fd1-ad67-4914-ada9-bdae1ed2f25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bundle",
   "language": "python",
   "name": "ospython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
