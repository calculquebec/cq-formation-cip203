{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4151d91-308a-4487-aba1-f4a365bd7965",
   "metadata": {},
   "source": [
    "# CIP203 - Maximizing GPU usage with MIGs, MPS, and Time-Slicing: \n",
    "## How to waste GPU cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b736e-ac92-43b3-a69e-36472cf7d90d",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* Why GPU cycles are wasted?\n",
    "* Potential reasons why codes under-utilize GPUs\n",
    "\n",
    "**Objectives**\n",
    "* Be aware of the GPU usage on the clusters\n",
    "* Understand the problem of GPU under-utilization\n",
    "* Become motivated to further make your code more GPU efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173181dd-0e7b-48b1-96c3-5aee387a3483",
   "metadata": {},
   "source": [
    "### Most common cases when GPUs are wasted on the Alliance' clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196047a5-1741-4ffa-8d09-f191466e0c3b",
   "metadata": {},
   "source": [
    "1. Users only think that they need a GPU, not even sure whether their code supports GPU, but request it anyway\n",
    "2. Users do know that their code has a GPU support, but don't know what it is, whether their problem is suitable on the GPU, but request it anyway\n",
    "3. Users moved their calculations to the GPU, parallelized their code, but the GPU utilization is low due to various reasons (small data set, slow I/O,inadequate CPU performance, etc) \n",
    "4. GPU utilization is sporadic/scattered, the code is not written well, making GPUs stay idle for very long time (sometimes days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dab330-db18-417d-99be-d1da5ce0c242",
   "metadata": {},
   "source": [
    "### Why GPU cycles are wasted ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797cddca-9b8f-415f-964f-f3ce6d0331b5",
   "metadata": {},
   "source": [
    "1. **I/O bottlenecks**\n",
    "   - slow data loading\n",
    "   - data stalls\n",
    "   - many small files\n",
    "3. **CPU bottlenecks**\n",
    "   - CPU-GPU communication (CPU can't keep up with the GPU's demand)\n",
    "   - synchronous operations\n",
    "5. **The problem is too small for GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424ecf4-959e-485f-87cf-5e52bdd43a66",
   "metadata": {},
   "source": [
    "### What is the solution ?\n",
    "<font color='blue'>**Increase the SIZE of the problem ?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09ea6d-0ccc-431e-a2f1-f1db6a46e4d8",
   "metadata": {},
   "source": [
    "Use highter resolution (e.g. in Computational Fluid Dynamics), larger batch size in Deep Learning, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ab842-7fce-4125-85c4-8c16f17d5b72",
   "metadata": {},
   "source": [
    "According to Gustafson's law, increasing the problem size while increasing number of computing cores can result in a much better scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106fae0-0c51-4d8a-b2d1-020b55a59839",
   "metadata": {},
   "source": [
    "#### ... well... sometimes it's not the best solution ! <br>\n",
    "Indeed, it does not make any sence to increase the size of the data set just so that the GPU runs more efficiently. In deep learning applications it may involve increasing the batch size, but often it does not make the problem any better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f044af2-a9d6-49b5-9044-99447dc8a68b",
   "metadata": {},
   "source": [
    "### What else can we do ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee5900-55a4-4735-8a25-7967e7d00243",
   "metadata": {},
   "source": [
    "One can fully move the calculations to the CPU cores only, thus excluding the GPUs from the setup completely. However, it often times requires users to re-write their codes (which sometimes is challenging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552c51e-86e2-40c9-a813-44ebb9448472",
   "metadata": {},
   "source": [
    "### Another solution: why not  <font color='red'>**share single GPU**</font> either between the user's processes or between different users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d83021-d0fa-4f02-962a-a20391420b48",
   "metadata": {},
   "source": [
    "#### Fortunately NVIDIA provides few solutions to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f458a-2e68-4d50-9bc8-9efb9a94b3af",
   "metadata": {},
   "source": [
    "- CUDA streams\n",
    "- NVIDIA Multi-Instance GPUs (MIGs)\n",
    "- Multi-Process Service (MPS)\n",
    "- Time-Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67f5b2-30d0-458b-870f-fae6730758e8",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032f82f-b09d-46dc-84f6-d261b9d74748",
   "metadata": {},
   "source": [
    "* **GPUs are wasted due to slow I/O, small problem size, etc**\n",
    "* **Increase efficiency = increase problem size ?**\n",
    "* **Instead why not share GPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0b001-27c3-4302-802a-019bb313619b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bundle",
   "language": "python",
   "name": "ospython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
